# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xjrp3lBb0yjrWW4h3x-LunrVxx0JU7mS
"""

import tensorflow as tf
import keras
from keras.layers import Dense, LSTM, Conv1D ,TimeDistributed, MaxPooling1D, Flatten
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

#데이터 수집
data_train_dust = pd.read_csv("data_2016~2019.csv", sep=",",encoding='cp949')
data_train_dust['year'] = np.NAN
data_train_dust['month'] = np.NAN
data_train_dust['day'] = np.NAN
data_train_dust.columns=['date','pm10','pm2.5','o3','no2','co','so2','year','month','day']
data_train_dust = data_train_dust[['date','year','month','day','so2','co','o3','no2','pm10','pm2.5']]
for i in range (data_train_dust.shape[0]):
    data_train_dust.loc[i, 'year'] = str(data_train_dust.loc[i, 'date']).split('-')[0]
    data_train_dust.loc[i, 'month'] = str(data_train_dust.loc[i, 'date']).split('-')[1]
    data_train_dust.loc[i, 'day'] = str(data_train_dust.loc[i, 'date']).split('-')[2]
data_train_dust=data_train_dust.drop(columns=['co','no2','o3','so2'])

data_train_dust=data_train_dust.fillna(method='ffill')
data_train_dust=data_train_dust.fillna(method='bfill')
data_train_dust.isnull().sum()
data_train_dust.info()
print(data_train_dust)

data_train=data_train_dust
data_train['date']=data_train['date'].str[:5]
data_train_=data_train[['pm10','pm2.5']]
plt.hist(data_train_)
plt.legend(['pm10','pm2.5'],fontsize=20)

pm10= np.array(data_train['pm10'])
pm25= np.array(data_train['pm2.5'])

#데이터 전처리
steps=6
features=1
def split_sequence(sequence, steps):
    x=[]
    y=[]
    for i in range(len(sequence)):
        end_index = i + steps
        if end_index > len(sequence)-1 :
            break
        seq_x, seq_y = sequence[i:end_index], sequence[end_index]
        x.append(seq_x)
        y.append(seq_y)
    return np.array(x), np.array(y)

x_pm10, y_pm10 = split_sequence(pm10, steps)
x_pm25, y_pm25 = split_sequence(pm25, steps)
print(x_pm10.shape, y_pm10.shape)
print(x_pm25.shape, y_pm25.shape)

#CNN-LSTM 코드 구현
subsequences =1
timesteps = x_pm10.shape[1]//1
x_pm10_sub=x_pm10.reshape((x_pm10.shape[0],subsequences,timesteps,1))
x_pm25_sub=x_pm25.reshape((x_pm25.shape[0],subsequences,timesteps,1))

model = keras.models.Sequential()
model.add(TimeDistributed(Conv1D(filters=128, kernel_size=3, strides=1,padding="same",
                      activation="relu"),input_shape=(None,x_pm10_sub.shape[2],x_pm10_sub.shape[3])))
model.add(TimeDistributed(MaxPooling1D(pool_size=2)))
model.add(TimeDistributed(Flatten()))
model.add(LSTM(300,activation="relu"))
model.add(Dense(1))
model.compile(loss='mean_absolute_error',optimizer="adam")
model.fit(x_pm10_sub, y_pm10, epochs=50, verbose=2)
model.fit(x_pm25_sub, y_pm25, epochs=50, verbose=2)
#'mean_absolute_error'    keras.losses.Huber()

#LSTM만을 활용한 딥러닝 코드 구현
model_2 = tf.keras.Sequential()
model_2.add(LSTM(100, activation='relu',input_shape=(6, 1),return_sequences=True))
model_2.add(LSTM(100, activation='relu',input_shape=(6, 1)))
model_2.add(Dense(1))
model_2.compile(loss='mean_absolute_error', optimizer='adam')
model_2.fit(x_pm10, y_pm10, epochs=50)
model_2.fit(x_pm25, y_pm25, epochs=50)

#test data 불러오기
data_test_dust = pd.read_csv("data_2020.csv", sep=",",encoding='cp949')
data_test_dust['year'] = np.NAN
data_test_dust['month'] = np.NAN
data_test_dust['day'] = np.NAN
data_test_dust.columns=['date','pm10','pm2.5','o3','no2','co','so2','year','month','day']
data_test_dust = data_test_dust[['date','year','month','day','so2','co','o3','no2','pm10','pm2.5']]
for i in range (data_test_dust.shape[0]):
    data_test_dust.loc[i, 'year'] = str(data_test_dust.loc[i, 'date']).split('-')[0]
    data_test_dust.loc[i, 'month'] = str(data_test_dust.loc[i, 'date']).split('-')[1]
    data_test_dust.loc[i, 'day'] = str(data_test_dust.loc[i, 'date']).split('-')[2]

data_test_dust=data_test_dust.fillna(method='ffill')
data_test_dust=data_test_dust.fillna(method='bfill')
data_test_dust.isnull().sum()
data_test_dust.info()
print(data_test_dust)

data_test=data_test_dust
data_test['date']=data_test['date'].str[:5]

#test data로 성능 측정
#미세먼지 모델
test_pm10=np.array(data_test["pm10"])
x_pm10_test, y_pm10_5test = split_sequence(test_pm10, steps)
timesteps = x_pm10_test.shape[1]//subsequences
x_pm10_test = x_pm10_test.reshape((x_pm10_test.shape[0], x_pm10_test.shape[1],features))
x_pm10_test_sub=x_pm10_test.reshape((x_pm10_test.shape[0],subsequences,timesteps,1))
a_pm10=model.predict(x_pm10_test_sub)
a_pm10=a_pm10.reshape((x_pm10_test_sub.shape[0],1))
b_pm10=model_2.predict(x_pm10_test)

#초미세먼지 모델
test_pm25=np.array(data_test["pm2.5"])
x_pm25_test, y_pm25_test = split_sequence(test_pm25, steps)
timesteps = x_pm25_test.shape[1]//subsequences
x_pm25_test = x_pm25_test.reshape((x_pm25_test.shape[0], x_pm25_test.shape[1],features))
x_pm25_test_sub=x_pm25_test.reshape((x_pm25_test.shape[0],subsequences,timesteps,1))
a_pm25=model.predict(x_pm25_test_sub)
a_pm25=a_pm25.reshape((x_pm25_test_sub.shape[0],1))
b_pm25=model_2.predict(x_pm25_test)

#모델 시각화
#미세먼지 시각화
plt.figure(figsize=(10,10))
plt.plot(a_pm10,color="blue")
plt.plot(b_pm10,color="red")
plt.plot(test_pm10,color="green")
plt.legend(['CNN-LSTM','LSTM','Actual'], loc='upper right', fontsize=20)
#plt.legend(['CNN-LSTM','Actual'], loc='upper right', fontsize=20)
#plt.legend(['LSTM','Actual'], loc='upper right', fontsize=20)
plt.ylim(0,100)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.show

#초미세먼지 시각화
plt.figure(figsize=(10,10))
#plt.plot(a_pm25,color="blue")
plt.plot(b_pm25,color="red")
plt.plot(test_pm25,color="green")
#plt.legend(['CNN-LSTM','LSTM','Actual'], loc='upper right', fontsize=20)
#plt.legend(['CNN-LSTM','Actual'], loc='upper right', fontsize=20)
plt.legend(['LSTM','Actual'], loc='upper right', fontsize=20)
plt.ylim(0,100)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
plt.show